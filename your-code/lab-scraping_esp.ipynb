{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Web-Scraping-Lab\" data-toc-modified-id=\"Web-Scraping-Lab-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Web Scraping Lab</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Useful-Resources\" data-toc-modified-id=\"Useful-Resources-1.0.1\"><span class=\"toc-item-num\">1.0.1&nbsp;&nbsp;</span>Useful Resources</a></span><ul class=\"toc-item\"><li><span><a href=\"#First-of-all,-gathering-our-tools.\" data-toc-modified-id=\"First-of-all,-gathering-our-tools.-1.0.1.1\"><span class=\"toc-item-num\">1.0.1.1&nbsp;&nbsp;</span>First of all, gathering our tools.</a></span></li><li><span><a href=\"#Challenge-1---Download,-parse-(using-BeautifulSoup),-and-print-the-content-from-the-Trending-Developers-page-from-GitHub:\" data-toc-modified-id=\"Challenge-1---Download,-parse-(using-BeautifulSoup),-and-print-the-content-from-the-Trending-Developers-page-from-GitHub:-1.0.1.2\"><span class=\"toc-item-num\">1.0.1.2&nbsp;&nbsp;</span>Challenge 1 - Download, parse (using BeautifulSoup), and print the content from the Trending Developers page from GitHub:</a></span></li><li><span><a href=\"#Display-the-names-of-the-trending-developers-retrieved-in-the-previous-step.\" data-toc-modified-id=\"Display-the-names-of-the-trending-developers-retrieved-in-the-previous-step.-1.0.1.3\"><span class=\"toc-item-num\">1.0.1.3&nbsp;&nbsp;</span>Display the names of the trending developers retrieved in the previous step.</a></span></li><li><span><a href=\"#Challenge-2---Display-the-trending-Python-repositories-in-GitHub\" data-toc-modified-id=\"Challenge-2---Display-the-trending-Python-repositories-in-GitHub-1.0.1.4\"><span class=\"toc-item-num\">1.0.1.4&nbsp;&nbsp;</span>Challenge 2 - Display the trending Python repositories in GitHub</a></span></li><li><span><a href=\"#Challenge-3---Display-all-the-image-links-from-Walt-Disney-wikipedia-page\" data-toc-modified-id=\"Challenge-3---Display-all-the-image-links-from-Walt-Disney-wikipedia-page-1.0.1.5\"><span class=\"toc-item-num\">1.0.1.5&nbsp;&nbsp;</span>Challenge 3 - Display all the image links from Walt Disney wikipedia page</a></span></li><li><span><a href=\"#Challenge-4---Retrieve-all-links-to-pages-on-Wikipedia-that-refer-to-some-kind-of-Python.\" data-toc-modified-id=\"Challenge-4---Retrieve-all-links-to-pages-on-Wikipedia-that-refer-to-some-kind-of-Python.-1.0.1.6\"><span class=\"toc-item-num\">1.0.1.6&nbsp;&nbsp;</span>Challenge 4 - Retrieve all links to pages on Wikipedia that refer to some kind of Python.</a></span></li><li><span><a href=\"#Challenge-5---Number-of-Titles-that-have-changed-in-the-United-States-Code-since-its-last-release-point\" data-toc-modified-id=\"Challenge-5---Number-of-Titles-that-have-changed-in-the-United-States-Code-since-its-last-release-point-1.0.1.7\"><span class=\"toc-item-num\">1.0.1.7&nbsp;&nbsp;</span>Challenge 5 - Number of Titles that have changed in the United States Code since its last release point</a></span></li><li><span><a href=\"#Challenge-6---A-Python-list-with-the-top-ten-FBI's-Most-Wanted-names\" data-toc-modified-id=\"Challenge-6---A-Python-list-with-the-top-ten-FBI's-Most-Wanted-names-1.0.1.8\"><span class=\"toc-item-num\">1.0.1.8&nbsp;&nbsp;</span>Challenge 6 - A Python list with the top ten FBI's Most Wanted names</a></span></li><li><span><a href=\"#Challenge-7---List-all-language-names-and-number-of-related-articles-in-the-order-they-appear-in-wikipedia.org\" data-toc-modified-id=\"Challenge-7---List-all-language-names-and-number-of-related-articles-in-the-order-they-appear-in-wikipedia.org-1.0.1.9\"><span class=\"toc-item-num\">1.0.1.9&nbsp;&nbsp;</span>Challenge 7 - List all language names and number of related articles in the order they appear in wikipedia.org</a></span></li><li><span><a href=\"#Challenge-8---A-list-with-the-different-kind-of-datasets-available-in-data.gov.uk\" data-toc-modified-id=\"Challenge-8---A-list-with-the-different-kind-of-datasets-available-in-data.gov.uk-1.0.1.10\"><span class=\"toc-item-num\">1.0.1.10&nbsp;&nbsp;</span>Challenge 8 - A list with the different kind of datasets available in data.gov.uk</a></span></li><li><span><a href=\"#Challenge-9---Top-10-languages-by-number-of-native-speakers-stored-in-a-Pandas-Dataframe\" data-toc-modified-id=\"Challenge-9---Top-10-languages-by-number-of-native-speakers-stored-in-a-Pandas-Dataframe-1.0.1.11\"><span class=\"toc-item-num\">1.0.1.11&nbsp;&nbsp;</span>Challenge 9 - Top 10 languages by number of native speakers stored in a Pandas Dataframe</a></span></li></ul></li><li><span><a href=\"#Stepping-up-the-game\" data-toc-modified-id=\"Stepping-up-the-game-1.0.2\"><span class=\"toc-item-num\">1.0.2&nbsp;&nbsp;</span>Stepping up the game</a></span><ul class=\"toc-item\"><li><span><a href=\"#Challenge-10---The-20-latest-earthquakes-info-(date,-time,-latitude,-longitude-and-region-name)-by-the-EMSC-as-a-pandas-dataframe\" data-toc-modified-id=\"Challenge-10---The-20-latest-earthquakes-info-(date,-time,-latitude,-longitude-and-region-name)-by-the-EMSC-as-a-pandas-dataframe-1.0.2.1\"><span class=\"toc-item-num\">1.0.2.1&nbsp;&nbsp;</span>Challenge 10 - The 20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe</a></span></li><li><span><a href=\"#Challenge-11---IMDB's-Top-250-data-(movie-name,-Initial-release,-director-name-and-stars)-as-a-pandas-dataframe\" data-toc-modified-id=\"Challenge-11---IMDB's-Top-250-data-(movie-name,-Initial-release,-director-name-and-stars)-as-a-pandas-dataframe-1.0.2.2\"><span class=\"toc-item-num\">1.0.2.2&nbsp;&nbsp;</span>Challenge 11 - IMDB's Top 250 data (movie name, Initial release, director name and stars) as a pandas dataframe</a></span></li><li><span><a href=\"#Challenge-12---Movie-name,-year-and-a-brief-summary-of-the-top-10-random-movies-(IMDB)-as-a-pandas-dataframe.\" data-toc-modified-id=\"Challenge-12---Movie-name,-year-and-a-brief-summary-of-the-top-10-random-movies-(IMDB)-as-a-pandas-dataframe.-1.0.2.3\"><span class=\"toc-item-num\">1.0.2.3&nbsp;&nbsp;</span>Challenge 12 - Movie name, year and a brief summary of the top 10 random movies (IMDB) as a pandas dataframe.</a></span></li><li><span><a href=\"#Challenge-13---Find-the-live-weather-report-(temperature,-wind-speed,-description-and-weather)-of-a-given-city.\" data-toc-modified-id=\"Challenge-13---Find-the-live-weather-report-(temperature,-wind-speed,-description-and-weather)-of-a-given-city.-1.0.2.4\"><span class=\"toc-item-num\">1.0.2.4&nbsp;&nbsp;</span>Challenge 13 - Find the live weather report (temperature, wind speed, description and weather) of a given city.</a></span></li><li><span><a href=\"#Challenge-14---Book-name,price-and-stock-availability-as-a-pandas-dataframe.\" data-toc-modified-id=\"Challenge-14---Book-name,price-and-stock-availability-as-a-pandas-dataframe.-1.0.2.5\"><span class=\"toc-item-num\">1.0.2.5&nbsp;&nbsp;</span>Challenge 14 - Book name,price and stock availability as a pandas dataframe.</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio de Web Scraping\n",
    "\n",
    "Encontrarás en este cuaderno algunos ejercicios de web scraping para practicar tus habilidades de scraping usando `requests` y `Beautiful Soup`.\n",
    "\n",
    "**Consejos:**\n",
    "\n",
    "- Verifica el [código de estado de la respuesta](https://http.cat/) para cada solicitud para asegurarte de haber obtenido el contenido previsto.\n",
    "- Observa el código HTML en cada solicitud para entender el tipo de información que estás obteniendo y su formato.\n",
    "- Busca patrones en el texto de respuesta para extraer los datos/información solicitados en cada pregunta.\n",
    "- Visita cada URL y echa un vistazo a su fuente a través de Chrome DevTools. Necesitarás identificar las etiquetas HTML, nombres de clases especiales, etc., utilizados para el contenido HTML que se espera extraer.\n",
    "- Revisa los selectores CSS.\n",
    "\n",
    "### Recursos Útiles\n",
    "- Documentación de la [biblioteca Requests](http://docs.python-requests.org/en/master/#the-user-guide)\n",
    "- [Doc de Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Lista de códigos de estado HTTP](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [Conceptos básicos de HTML](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [Conceptos básicos de CSS](https://www.cssbasics.com/#page_start)\n",
    "\n",
    "#### Primero que todo, reuniendo nuestras herramientas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ **Nuevamente, recuerda limitar tu salida antes de la entrega para que tu código no se pierda en la salida.**\n",
    "\n",
    "#### Desafío 1 - Descargar, analizar (usando BeautifulSoup) e imprimir el contenido de la página de Desarrolladores en Tendencia de GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/developers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_html=requests.get(url).text\n",
    "soup = BeautifulSoup(github_html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Muestra los nombres de los desarrolladores en tendencia recuperados en el paso anterior.\n",
    "\n",
    "Tu salida debe ser una lista de Python con los nombres de los desarrolladores. Cada nombre no debe contener ninguna etiqueta HTML.\n",
    "\n",
    "**Instrucciones:**\n",
    "\n",
    "1. Descubre la etiqueta HTML y los nombres de clase usados para los nombres de los desarrolladores. Puedes lograr esto usando Chrome DevTools.\n",
    "\n",
    "1. Usa BeautifulSoup para extraer todos los elementos HTML que contienen los nombres de los desarrolladores.\n",
    "\n",
    "1. Utiliza técnicas de manipulación de cadenas para reemplazar espacios en blanco y saltos de línea (es decir, `\\n`) en el *texto* de cada elemento HTML. Usa una lista para almacenar los nombres limpios.\n",
    "\n",
    "1. Imprime la lista de nombres.\n",
    "\n",
    "Tu salida debería lucir como abajo (con nombres diferentes):\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (神楽坂覚々)',\n",
    " 'script-8']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sebastian Raschka', 'LangChain4j', 'Norman Maurer', 'doronz88', 'JJ Kasper', 'Miguel Beltran', 'Vik Paruchuri', 'Arthur', 'Holt Skinner', 'Huang Huang', 'Aliaksandr Valialkin', 'Massimiliano Pippi', 'Jack Lloyd', 'Rich Harris', 'Tobias Klauser', 'Lukas Masuch', 'Charlie Marsh', 'Steven Silvester', 'Matthias Seitz', 'Justin Lebar', 'Mattias Wadman', 'David Sherret', 'Gal Schlezinger', 'Mitchell Hashimoto', 'awaelchli']\n"
     ]
    }
   ],
   "source": [
    "# Tu código aquí\n",
    "names = list(map(lambda node: str(node.text).strip(),soup.select('h1.h3.lh-condensed.lh-condensed > a.Link')))\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desafío 2 - Mostrar los repositorios de Python en tendencia en GitHub\n",
    "\n",
    "Los pasos para resolver este problema son similares al anterior, excepto que necesitas encontrar los nombres de los repositorios en lugar de los nombres de los desarrolladores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url2 = 'https://github.com/trending/python?since=daily'\n",
    "datos2 = requests.get(f\"{url2}\").text\n",
    "soup2 = BeautifulSoup(datos2, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cover-agent', 'khoj', 'searxng', 'MiniCPM-V', 'CVE-2024-21683-RCE', 'omniglue', 'ungoogled-chromium', 'bisheng', 'nvda', 'ragflow', 'seismometer', 'core', 'accelerate', 'taipy', 'corenet', 'LaVague', 'gpt-researcher', 'krita-ai-diffusion', 'azure-sdk-for-python', 'unsloth', 'TagStudio', 'pathway', 'Python', 'Python-100-Days', 'sqlmesh']\n"
     ]
    }
   ],
   "source": [
    "repos = list(map(lambda node: str(node.attrs['href']).strip().split('/')[-1],soup2.select('h2.h3.lh-condensed.lh-condensed > a.Link')))\n",
    "print(repos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desafío 3 - Mostrar todos los enlaces de imágenes de la página de Wikipedia de Walt Disney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url3 = 'https://en.wikipedia.org/wiki/Walt_Disney'\n",
    "disney = requests.get(f\"{url3}\").text\n",
    "soup3 = BeautifulSoup(disney, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://avatars.githubusercontent.com/u/21198860?s=40&v=4', 'https://avatars.githubusercontent.com/u/170273941?s=40&v=4', 'https://avatars.githubusercontent.com/u/108689937?s=40&v=4', 'https://avatars.githubusercontent.com/u/42740235?s=40&v=4', 'https://avatars.githubusercontent.com/u/30233365?s=40&v=4', 'https://avatars.githubusercontent.com/u/6413477?s=40&v=4', 'https://avatars.githubusercontent.com/u/65192171?s=40&v=4', 'https://avatars.githubusercontent.com/u/22633385?s=40&v=4', 'https://avatars.githubusercontent.com/u/51520018?s=40&v=4', 'https://avatars.githubusercontent.com/u/68677082?s=40&v=4', 'https://avatars.githubusercontent.com/u/554536?s=40&v=4', 'https://avatars.githubusercontent.com/u/20240?s=40&v=4', 'https://avatars.githubusercontent.com/u/1594191?s=40&v=4', 'https://avatars.githubusercontent.com/u/3876218?s=40&v=4', 'https://avatars.githubusercontent.com/in/29110?s=40&v=4', 'https://avatars.githubusercontent.com/u/28106858?s=40&v=4', 'https://avatars.githubusercontent.com/u/19372848?s=40&v=4', 'https://avatars.githubusercontent.com/u/5380770?s=40&v=4', 'https://avatars.githubusercontent.com/u/157115220?s=40&v=4', 'https://avatars.githubusercontent.com/u/92843231?s=40&v=4', 'https://avatars.githubusercontent.com/u/101872898?s=40&v=4', 'https://avatars.githubusercontent.com/u/6743942?s=40&v=4', 'https://avatars.githubusercontent.com/u/31920396?s=40&v=4', 'https://avatars.githubusercontent.com/u/1305560?s=40&v=4', 'https://avatars.githubusercontent.com/u/40727284?s=40&v=4', 'https://avatars.githubusercontent.com/u/9345273?s=40&v=4', 'https://avatars.githubusercontent.com/u/10319700?s=40&v=4', 'https://avatars.githubusercontent.com/u/2191538?s=40&v=4', 'https://avatars.githubusercontent.com/u/3382757?s=40&v=4', 'https://avatars.githubusercontent.com/u/18637871?s=40&v=4', 'https://avatars.githubusercontent.com/u/8371743?s=40&v=4', 'https://avatars.githubusercontent.com/u/13868973?s=40&v=4', 'https://avatars.githubusercontent.com/u/110683040?s=40&v=4', 'https://avatars.githubusercontent.com/u/4166475?s=40&v=4', 'https://avatars.githubusercontent.com/u/14154141?s=40&v=4', 'https://avatars.githubusercontent.com/u/7090342?s=40&v=4', 'https://avatars.githubusercontent.com/u/3491346?s=40&v=4', 'https://avatars.githubusercontent.com/u/3049216?s=40&v=4', 'https://avatars.githubusercontent.com/u/12318111?s=40&v=4', 'https://avatars.githubusercontent.com/u/8089971?s=40&v=4', 'https://avatars.githubusercontent.com/u/93570324?s=40&v=4', 'https://avatars.githubusercontent.com/u/33142505?s=40&v=4', 'https://avatars.githubusercontent.com/u/40135906?s=40&v=4', 'https://avatars.githubusercontent.com/u/106454604?s=40&v=4', 'https://avatars.githubusercontent.com/u/28059272?s=40&v=4', 'https://avatars.githubusercontent.com/u/36572844?s=40&v=4', 'https://avatars.githubusercontent.com/u/8771332?s=40&v=4', 'https://avatars.githubusercontent.com/u/768790?s=40&v=4', 'https://avatars.githubusercontent.com/u/1444314?s=40&v=4', 'https://avatars.githubusercontent.com/u/663432?s=40&v=4', 'https://avatars.githubusercontent.com/u/195327?s=40&v=4', 'https://avatars.githubusercontent.com/u/14281572?s=40&v=4', 'https://avatars.githubusercontent.com/u/6771947?s=40&v=4', 'https://avatars.githubusercontent.com/u/7831895?s=40&v=4', 'https://avatars.githubusercontent.com/u/35901082?s=40&v=4', 'https://avatars.githubusercontent.com/u/13534540?s=40&v=4', 'https://avatars.githubusercontent.com/u/57196510?s=40&v=4', 'https://avatars.githubusercontent.com/u/6229650?s=40&v=4', 'https://avatars.githubusercontent.com/u/88036007?s=40&v=4', 'https://avatars.githubusercontent.com/u/37588363?s=40&v=4', 'https://avatars.githubusercontent.com/u/90181748?s=40&v=4', 'https://avatars.githubusercontent.com/u/45910030?s=40&v=4', 'https://avatars.githubusercontent.com/u/88906996?s=40&v=4', 'https://avatars.githubusercontent.com/u/18603245?s=40&v=4', 'https://avatars.githubusercontent.com/u/26336?s=40&v=4', 'https://avatars.githubusercontent.com/u/767425?s=40&v=4', 'https://avatars.githubusercontent.com/u/3453449?s=40&v=4', 'https://avatars.githubusercontent.com/u/2064161?s=40&v=4', 'https://avatars.githubusercontent.com/u/52970539?s=40&v=4', 'https://avatars.githubusercontent.com/u/20685007?s=40&v=4', 'https://avatars.githubusercontent.com/u/56654600?s=40&v=4', 'https://avatars.githubusercontent.com/u/36925557?s=40&v=4', 'https://avatars.githubusercontent.com/u/22163205?s=40&v=4', 'https://avatars.githubusercontent.com/u/13554167?s=40&v=4', 'https://avatars.githubusercontent.com/u/91344214?s=40&v=4', 'https://avatars.githubusercontent.com/u/16700452?s=40&v=4', 'https://avatars.githubusercontent.com/u/37247296?s=40&v=4', 'https://avatars.githubusercontent.com/in/29110?s=40&v=4', 'https://avatars.githubusercontent.com/u/6485914?s=40&v=4', 'https://avatars.githubusercontent.com/u/15424198?s=40&v=4', 'https://avatars.githubusercontent.com/u/151779294?s=40&v=4', 'https://avatars.githubusercontent.com/u/8367836?s=40&v=4', 'https://avatars.githubusercontent.com/u/22294122?s=40&v=4', 'https://avatars.githubusercontent.com/u/1050156?s=40&v=4', 'https://avatars.githubusercontent.com/u/53356347?s=40&v=4', 'https://avatars.githubusercontent.com/u/70930885?s=40&v=4', 'https://avatars.githubusercontent.com/u/31998003?s=40&v=4', 'https://avatars.githubusercontent.com/u/14350651?s=40&v=4', 'https://avatars.githubusercontent.com/u/23090290?s=40&v=4', 'https://avatars.githubusercontent.com/u/107991372?s=40&v=4', 'https://avatars.githubusercontent.com/u/43654321?s=40&v=4', 'https://avatars.githubusercontent.com/u/19970582?s=40&v=4', 'https://avatars.githubusercontent.com/u/42650258?s=40&v=4', 'https://avatars.githubusercontent.com/u/46939827?s=40&v=4', 'https://avatars.githubusercontent.com/u/7898215?s=40&v=4', 'https://avatars.githubusercontent.com/u/162526?s=40&v=4', 'https://avatars.githubusercontent.com/u/91694323?s=40&v=4', 'https://avatars.githubusercontent.com/u/60973030?s=40&v=4', 'https://avatars.githubusercontent.com/u/28102878?s=40&v=4', 'https://avatars.githubusercontent.com/u/104143901?s=40&v=4', 'https://avatars.githubusercontent.com/u/40573492?s=40&v=4', 'https://avatars.githubusercontent.com/u/111756570?s=40&v=4', 'https://avatars.githubusercontent.com/u/8168856?s=40&v=4', 'https://avatars.githubusercontent.com/u/1170130?s=40&v=4', 'https://avatars.githubusercontent.com/in/29110?s=40&v=4', 'https://avatars.githubusercontent.com/u/90651616?s=40&v=4', 'https://avatars.githubusercontent.com/u/112542130?s=40&v=4', 'https://avatars.githubusercontent.com/u/83634399?s=40&v=4', 'https://avatars.githubusercontent.com/u/7474657?s=40&v=4', 'https://avatars.githubusercontent.com/u/13017944?s=40&v=4', 'https://avatars.githubusercontent.com/u/10865729?s=40&v=4', 'https://avatars.githubusercontent.com/u/599268?s=40&v=4', 'https://avatars.githubusercontent.com/u/2331406?s=40&v=4', 'https://avatars.githubusercontent.com/u/7747479?s=40&v=4', 'https://avatars.githubusercontent.com/u/8205034?s=40&v=4', 'https://avatars.githubusercontent.com/u/6326532?s=40&v=4', 'https://avatars.githubusercontent.com/u/5644753?s=40&v=4', 'https://avatars.githubusercontent.com/u/46752250?s=40&v=4']\n"
     ]
    }
   ],
   "source": [
    "images = list(map(lambda node: str(node.attrs['src']), soup2.select('img')))\n",
    "print(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desafío 4 - Recuperar todos los enlaces a páginas en Wikipedia que se refieren a algún tipo de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "url4 ='https://en.wikipedia.org/wiki/Python' \n",
    "python = requests.get(f\"{url4}\").text\n",
    "soup4 = BeautifulSoup(python, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/login?return_to=https%3A%2F%2Fgithub.com%2Ftrending%2Fpython%3Fsince%3Ddaily', '/login?return_to=https%3A%2F%2Fgithub.com%2Ftrending%2Fpython%3Fsince%3Ddaily', '/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2Ftrending%2Fpython&source=header', '/trending/python?since=daily&spoken_language_code=ab', '/trending/python?since=daily&spoken_language_code=aa', '/trending/python?since=daily&spoken_language_code=af', '/trending/python?since=daily&spoken_language_code=ak', '/trending/python?since=daily&spoken_language_code=sq', '/trending/python?since=daily&spoken_language_code=am', '/trending/python?since=daily&spoken_language_code=ar', '/trending/python?since=daily&spoken_language_code=an', '/trending/python?since=daily&spoken_language_code=hy', '/trending/python?since=daily&spoken_language_code=as', '/trending/python?since=daily&spoken_language_code=av', '/trending/python?since=daily&spoken_language_code=ae', '/trending/python?since=daily&spoken_language_code=ay', '/trending/python?since=daily&spoken_language_code=az', '/trending/python?since=daily&spoken_language_code=bm', '/trending/python?since=daily&spoken_language_code=ba', '/trending/python?since=daily&spoken_language_code=eu', '/trending/python?since=daily&spoken_language_code=be', '/trending/python?since=daily&spoken_language_code=bn', '/trending/python?since=daily&spoken_language_code=bh', '/trending/python?since=daily&spoken_language_code=bi', '/trending/python?since=daily&spoken_language_code=bs', '/trending/python?since=daily&spoken_language_code=br', '/trending/python?since=daily&spoken_language_code=bg', '/trending/python?since=daily&spoken_language_code=my', '/trending/python?since=daily&spoken_language_code=ca', '/trending/python?since=daily&spoken_language_code=ch', '/trending/python?since=daily&spoken_language_code=ce', '/trending/python?since=daily&spoken_language_code=ny', '/trending/python?since=daily&spoken_language_code=zh', '/trending/python?since=daily&spoken_language_code=cv', '/trending/python?since=daily&spoken_language_code=kw', '/trending/python?since=daily&spoken_language_code=co', '/trending/python?since=daily&spoken_language_code=cr', '/trending/python?since=daily&spoken_language_code=hr', '/trending/python?since=daily&spoken_language_code=cs', '/trending/python?since=daily&spoken_language_code=da', '/trending/python?since=daily&spoken_language_code=dv', '/trending/python?since=daily&spoken_language_code=nl', '/trending/python?since=daily&spoken_language_code=dz', '/trending/python?since=daily&spoken_language_code=en', '/trending/python?since=daily&spoken_language_code=eo', '/trending/python?since=daily&spoken_language_code=et', '/trending/python?since=daily&spoken_language_code=ee', '/trending/python?since=daily&spoken_language_code=fo', '/trending/python?since=daily&spoken_language_code=fj', '/trending/python?since=daily&spoken_language_code=fi', '/trending/python?since=daily&spoken_language_code=fr', '/trending/python?since=daily&spoken_language_code=ff', '/trending/python?since=daily&spoken_language_code=gl', '/trending/python?since=daily&spoken_language_code=ka', '/trending/python?since=daily&spoken_language_code=de', '/trending/python?since=daily&spoken_language_code=el', '/trending/python?since=daily&spoken_language_code=gn', '/trending/python?since=daily&spoken_language_code=gu', '/trending/python?since=daily&spoken_language_code=ht', '/trending/python?since=daily&spoken_language_code=ha', '/trending/python?since=daily&spoken_language_code=he', '/trending/python?since=daily&spoken_language_code=hz', '/trending/python?since=daily&spoken_language_code=hi', '/trending/python?since=daily&spoken_language_code=ho', '/trending/python?since=daily&spoken_language_code=hu', '/trending/python?since=daily&spoken_language_code=ia', '/trending/python?since=daily&spoken_language_code=id', '/trending/python?since=daily&spoken_language_code=ie', '/trending/python?since=daily&spoken_language_code=ga', '/trending/python?since=daily&spoken_language_code=ig', '/trending/python?since=daily&spoken_language_code=ik', '/trending/python?since=daily&spoken_language_code=io', '/trending/python?since=daily&spoken_language_code=is', '/trending/python?since=daily&spoken_language_code=it', '/trending/python?since=daily&spoken_language_code=iu', '/trending/python?since=daily&spoken_language_code=ja', '/trending/python?since=daily&spoken_language_code=jv', '/trending/python?since=daily&spoken_language_code=kl', '/trending/python?since=daily&spoken_language_code=kn', '/trending/python?since=daily&spoken_language_code=kr', '/trending/python?since=daily&spoken_language_code=ks', '/trending/python?since=daily&spoken_language_code=kk', '/trending/python?since=daily&spoken_language_code=km', '/trending/python?since=daily&spoken_language_code=ki', '/trending/python?since=daily&spoken_language_code=rw', '/trending/python?since=daily&spoken_language_code=ky', '/trending/python?since=daily&spoken_language_code=kv', '/trending/python?since=daily&spoken_language_code=kg', '/trending/python?since=daily&spoken_language_code=ko', '/trending/python?since=daily&spoken_language_code=ku', '/trending/python?since=daily&spoken_language_code=kj', '/trending/python?since=daily&spoken_language_code=la', '/trending/python?since=daily&spoken_language_code=lb', '/trending/python?since=daily&spoken_language_code=lg', '/trending/python?since=daily&spoken_language_code=li', '/trending/python?since=daily&spoken_language_code=ln', '/trending/python?since=daily&spoken_language_code=lo', '/trending/python?since=daily&spoken_language_code=lt', '/trending/python?since=daily&spoken_language_code=lu', '/trending/python?since=daily&spoken_language_code=lv', '/trending/python?since=daily&spoken_language_code=gv', '/trending/python?since=daily&spoken_language_code=mk', '/trending/python?since=daily&spoken_language_code=mg', '/trending/python?since=daily&spoken_language_code=ms', '/trending/python?since=daily&spoken_language_code=ml', '/trending/python?since=daily&spoken_language_code=mt', '/trending/python?since=daily&spoken_language_code=mi', '/trending/python?since=daily&spoken_language_code=mr', '/trending/python?since=daily&spoken_language_code=mh', '/trending/python?since=daily&spoken_language_code=mn', '/trending/python?since=daily&spoken_language_code=na', '/trending/python?since=daily&spoken_language_code=nv', '/trending/python?since=daily&spoken_language_code=nd', '/trending/python?since=daily&spoken_language_code=ne', '/trending/python?since=daily&spoken_language_code=ng', '/trending/python?since=daily&spoken_language_code=nb', '/trending/python?since=daily&spoken_language_code=nn', '/trending/python?since=daily&spoken_language_code=no', '/trending/python?since=daily&spoken_language_code=ii', '/trending/python?since=daily&spoken_language_code=nr', '/trending/python?since=daily&spoken_language_code=oc', '/trending/python?since=daily&spoken_language_code=oj', '/trending/python?since=daily&spoken_language_code=cu', '/trending/python?since=daily&spoken_language_code=om', '/trending/python?since=daily&spoken_language_code=or', '/trending/python?since=daily&spoken_language_code=os', '/trending/python?since=daily&spoken_language_code=pa', '/trending/python?since=daily&spoken_language_code=pi', '/trending/python?since=daily&spoken_language_code=fa', '/trending/python?since=daily&spoken_language_code=pl', '/trending/python?since=daily&spoken_language_code=ps', '/trending/python?since=daily&spoken_language_code=pt', '/trending/python?since=daily&spoken_language_code=qu', '/trending/python?since=daily&spoken_language_code=rm', '/trending/python?since=daily&spoken_language_code=rn', '/trending/python?since=daily&spoken_language_code=ro', '/trending/python?since=daily&spoken_language_code=ru', '/trending/python?since=daily&spoken_language_code=sa', '/trending/python?since=daily&spoken_language_code=sc', '/trending/python?since=daily&spoken_language_code=sd', '/trending/python?since=daily&spoken_language_code=se', '/trending/python?since=daily&spoken_language_code=sm', '/trending/python?since=daily&spoken_language_code=sg', '/trending/python?since=daily&spoken_language_code=sr', '/trending/python?since=daily&spoken_language_code=gd', '/trending/python?since=daily&spoken_language_code=sn', '/trending/python?since=daily&spoken_language_code=si', '/trending/python?since=daily&spoken_language_code=sk', '/trending/python?since=daily&spoken_language_code=sl', '/trending/python?since=daily&spoken_language_code=so', '/trending/python?since=daily&spoken_language_code=st', '/trending/python?since=daily&spoken_language_code=es', '/trending/python?since=daily&spoken_language_code=su', '/trending/python?since=daily&spoken_language_code=sw', '/trending/python?since=daily&spoken_language_code=ss', '/trending/python?since=daily&spoken_language_code=sv', '/trending/python?since=daily&spoken_language_code=ta', '/trending/python?since=daily&spoken_language_code=te', '/trending/python?since=daily&spoken_language_code=tg', '/trending/python?since=daily&spoken_language_code=th', '/trending/python?since=daily&spoken_language_code=ti', '/trending/python?since=daily&spoken_language_code=bo', '/trending/python?since=daily&spoken_language_code=tk', '/trending/python?since=daily&spoken_language_code=tl', '/trending/python?since=daily&spoken_language_code=tn', '/trending/python?since=daily&spoken_language_code=to', '/trending/python?since=daily&spoken_language_code=tr', '/trending/python?since=daily&spoken_language_code=ts', '/trending/python?since=daily&spoken_language_code=tt', '/trending/python?since=daily&spoken_language_code=tw', '/trending/python?since=daily&spoken_language_code=ty', '/trending/python?since=daily&spoken_language_code=ug', '/trending/python?since=daily&spoken_language_code=uk', '/trending/python?since=daily&spoken_language_code=ur', '/trending/python?since=daily&spoken_language_code=uz', '/trending/python?since=daily&spoken_language_code=ve', '/trending/python?since=daily&spoken_language_code=vi', '/trending/python?since=daily&spoken_language_code=vo', '/trending/python?since=daily&spoken_language_code=wa', '/trending/python?since=daily&spoken_language_code=cy', '/trending/python?since=daily&spoken_language_code=wo', '/trending/python?since=daily&spoken_language_code=fy', '/trending/python?since=daily&spoken_language_code=xh', '/trending/python?since=daily&spoken_language_code=yi', '/trending/python?since=daily&spoken_language_code=yo', '/trending/python?since=daily&spoken_language_code=za', '/trending/python?since=daily&spoken_language_code=zu', '/trending?since=daily', '/trending/python-console?since=daily', '/trending/python-traceback?since=daily', 'https://github.com/trending/python?since=daily', 'https://github.com/trending/python?since=weekly', 'https://github.com/trending/python?since=monthly', '/login?return_to=%2FAzure%2Fazure-sdk-for-python', '/Azure/azure-sdk-for-python', 'https://docs.microsoft.com/python/azure/', 'https://azure.github.io/azure-sdk-for-python', '/Azure/azure-sdk-for-python/stargazers', '/Azure/azure-sdk-for-python/forks', '/login?return_to=%2Fgeekcomputers%2FPython', '/geekcomputers/Python', '/geekcomputers/Python/stargazers', '/geekcomputers/Python/forks', '/login?return_to=%2Fjackfrued%2FPython-100-Days', '/jackfrued/Python-100-Days', '/jackfrued/Python-100-Days/stargazers', '/jackfrued/Python-100-Days/forks']\n"
     ]
    }
   ],
   "source": [
    "def parseNode(node):\n",
    "    try:\n",
    "        return { 'href': str(node.attrs['href']) or '', 'text': str(node.text) or '' }\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "links = list(map(parseNode,soup2.select('a')))\n",
    "\n",
    "pythons = list(map(lambda node: node['href'],filter(lambda node: node != None and 'python' in node['text'].strip().lower() or 'python' in node['href'].strip().lower(),links)))\n",
    "print(pythons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desafío 5 - Número de Títulos que han cambiado en el Código de los Estados Unidos desde su último punto de lanzamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url5 = 'http://uscode.house.gov/download/download.shtml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Title 26 - Internal Revenue Code', 'Title 42 - The Public Health and Welfare']\n"
     ]
    }
   ],
   "source": [
    "python = requests.get(f\"{url5}\").text\n",
    "soup5 = BeautifulSoup(python, 'html.parser')\n",
    "\n",
    "entries = list(map(lambda node: str(node.text).strip(), soup5.select('div.usctitlechanged')))\n",
    "print(entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desafío 6 - Una lista de Python con los diez nombres más buscados por el FBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exerciseS\n",
    "url7 = 'https://www.fbi.gov/wanted/topten'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted = requests.get(f\"{url7}\", headers={'Referer': 'https://www.fbi.gov/++theme++fbi-youtube-fix/css/index.css?v=10.1'}).text\n",
    "soup7 = BeautifulSoup(wanted, 'html.parser')\n",
    "wantedtag = soup7.find_all('h3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El FBI te ha bloqueado\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "cacos = list(map(lambda node: str(node.text).strip(), soup7.select('h3.title > a')))\n",
    "if len(cacos) == 0:\n",
    "    print(\"El FBI te ha bloqueado\")\n",
    "print(cacos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desafío 7 - Listar todos los nombres de idiomas y el número de artículos relacionados en el orden en que aparecen en wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url8 = 'https://www.wikipedia.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = requests.get(f\"{url8}\")\n",
    "languages.encoding = 'utf-8'\n",
    "soup8 = BeautifulSoup(languages.text, 'html.parser')\n",
    "langlist = soup8.find_all(\"div\", {\"class\": f\"central-featured-lang\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'language': 'English', 'amount': '6,796,000'}, {'language': 'Русский', 'amount': '1\\xa0969\\xa0000'}, {'language': '日本語', 'amount': '1,407,000'}, {'language': 'Español', 'amount': '1.938.000'}, {'language': 'Deutsch', 'amount': '2.891.000'}, {'language': 'Français', 'amount': '2\\u202f598\\u202f000'}, {'language': 'Italiano', 'amount': '1.853.000'}, {'language': '中文', 'amount': '1,409,000'}, {'language': 'فارسی', 'amount': '۹۹۵٬۰۰۰'}, {'language': 'Português', 'amount': '1.120.000'}]\n"
     ]
    }
   ],
   "source": [
    "langs = list(map(lambda node: { 'language': node.select('strong')[0].text, 'amount': node.select('small')[0].text.split('+')[0] }, soup8.select('a.link-box')))\n",
    "print(langs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desafío 8 - Una lista con los diferentes tipos de conjuntos de datos disponibles en data.gov.uk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url82 = 'https://data.gov.uk/'\n",
    "dats = requests.get(f\"{url82}\")\n",
    "soup8 = BeautifulSoup(dats.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Business and economy', 'Crime and justice', 'Defence', 'Education', 'Environment', 'Government', 'Government spending', 'Health', 'Mapping', 'Society', 'Towns and cities', 'Transport', 'Digital service performance', 'Government reference data']\n"
     ]
    }
   ],
   "source": [
    "conjData = list(map(lambda node: str(node.text).strip(), soup8.select('h3.govuk-heading-s.dgu-topics__heading > a')))\n",
    "print(conjData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desafío 9 - Los 10 idiomas con más hablantes nativos almacenados en un DataFrame de Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url9 = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'\n",
    "tenlang = requests.get(url9)\n",
    "soup9 = BeautifulSoup(tenlang.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               name  speakers\n",
      "0  Mandarin Chinese       941\n",
      "1           Spanish       486\n",
      "2           English       380\n",
      "3             Hindi       345\n",
      "4           Bengali       237\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def parseRow(row):\n",
    "    tds = row.select('td')\n",
    "    if len(tds) < 2:\n",
    "        return None\n",
    "    return {'name': tds[0].select_one('a').text, 'speakers': int(tds[1].text)}\n",
    "\n",
    "table = list(filter(lambda node: 'Languages with at least 50 million first-language speakers' in node.text, soup9.select('table > caption')))[0].parent\n",
    "rows = table.select('tr')\n",
    "rows = list(map(parseRow, rows))\n",
    "\n",
    "rows = rows[1:6]\n",
    "\n",
    "rowsDf = pd.DataFrame(data=rows)\n",
    "print(rowsDf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subiendo el nivel\n",
    "#### Desafío 10 - La información de los 20 últimos terremotos (fecha, hora, latitud, longitud y nombre de la región) por el EMSC como un dataframe de pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "#url7 = 'https://www.emsc-csem.org/Earthquake/'\n",
    "url7 = \"https://earthquaketrack.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       time                     on\n",
      "0   2024-05-25 08:19:07 UTC               Luquillo\n",
      "1   2024-05-25 08:08:59 UTC             Kamtsjatka\n",
      "2   2024-05-25 07:52:08 UTC              Catamarca\n",
      "3   2024-05-25 07:43:11 UTC                  Loiza\n",
      "4   2024-05-25 07:37:21 UTC           Maluku Utara\n",
      "5   2024-05-25 07:28:26 UTC                  Loiza\n",
      "6   2024-05-25 06:56:38 UTC                       \n",
      "7   2024-05-25 06:53:53 UTC          La Altagracia\n",
      "8   2024-05-25 05:55:51 UTC             West Papua\n",
      "9   2024-05-25 05:43:31 UTC                       \n",
      "10  2024-05-25 05:03:27 UTC               Coquimbo\n",
      "11  2024-05-25 04:33:09 UTC           Bougainville\n",
      "12  2024-05-25 02:49:43 UTC                       \n",
      "13  2024-05-25 02:20:08 UTC           Maluku Utara\n",
      "14  2024-05-25 01:05:45 UTC                Hatillo\n",
      "15  2024-05-25 00:10:13 UTC                   Aceh\n",
      "16  2024-05-24 23:23:24 UTC                       \n",
      "17  2024-05-24 22:51:21 UTC             West Papua\n",
      "18  2024-05-24 18:59:32 UTC                       \n",
      "19  2024-05-24 17:35:24 UTC               Calabria\n",
      "20  2024-05-24 17:23:03 UTC              La Romana\n",
      "21  2024-05-24 17:07:12 UTC                 Taiwan\n",
      "22  2024-05-24 17:06:37 UTC                 Taiwan\n",
      "23  2024-05-24 15:51:32 UTC            New Ireland\n",
      "24  2024-05-24 14:54:26 UTC                Katanga\n",
      "25  2024-05-24 13:58:49 UTC  Transbaikal Territory\n"
     ]
    }
   ],
   "source": [
    "# La página me bloqueó el acceso. He usado otra\n",
    "dats = requests.get(f\"{url7}\")\n",
    "soup8 = BeautifulSoup(dats.content, 'html.parser')\n",
    "\n",
    "temblores = list(map(lambda node: {'time': node.select_one('abbr.timeago').text.strip(), 'on': node.select('a')[2].text}, soup8.select('div.quake-info.col')))\n",
    "\n",
    "rowsDf = pd.DataFrame(data=temblores)\n",
    "print(rowsDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desafío 11 - Datos del Top 250 de IMDB (nombre de la película, lanzamiento inicial, nombre del director y estrellas) como un dataframe de pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "url11 = 'https://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  name  \\\n",
      "0                          1. The Shawshank Redemption   \n",
      "1                                     2. The Godfather   \n",
      "2                                   3. The Dark Knight   \n",
      "3                             4. The Godfather Part II   \n",
      "4                                      5. 12 Angry Men   \n",
      "..                                                 ...   \n",
      "220                                      221. La haine   \n",
      "221                                 222. Before Sunset   \n",
      "222                   223. The Best Years of Our Lives   \n",
      "223  224. Pirates of the Caribbean: The Curse of th...   \n",
      "224                                  225. The Exorcist   \n",
      "\n",
      "                     release stars  \n",
      "0            1994\\n2h 22m\\nR   9.3  \n",
      "1            1972\\n2h 55m\\nR   9.2  \n",
      "2        2008\\n2h 32m\\nPG-13   9.0  \n",
      "3            1974\\n3h 22m\\nR   9.0  \n",
      "4     1957\\n1h 36m\\nApproved   9.0  \n",
      "..                       ...   ...  \n",
      "220  1995\\n1h 38m\\nNot Rated   8.1  \n",
      "221          2004\\n1h 20m\\nR   8.1  \n",
      "222   1946\\n2h 50m\\nApproved   8.1  \n",
      "223      2003\\n2h 23m\\nPG-13   8.1  \n",
      "224           1973\\n2h 2m\\nR   8.1  \n",
      "\n",
      "[225 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "driver = webdriver.Firefox()\n",
    "driver.get(url11)\n",
    "\n",
    "elements = driver.find_elements(By.CSS_SELECTOR,'ul.ipc-metadata-list > li')\n",
    "\n",
    "def parsePeli(node):\n",
    "    name = node.find_element(By.CSS_SELECTOR,'h3.ipc-title__text').text\n",
    "    release = node.find_elements(By.CSS_SELECTOR,'div.cli-title-metadata')[0].text\n",
    "    stars = node.find_element(By.CSS_SELECTOR, '[data-testid=\"ratingGroup--imdb-rating\"]').text.split()[0].replace(',', '.')\n",
    "    # Si intento sacar el autor la página me bloquea por demasiadas solicitudes. Te dejo el código que usaba para abrir el modal aquí\n",
    "    #button = node.find_element(By.CSS_SELECTOR, 'button.ipc-icon-button.cli-info-icon.ipc-icon-button--base.ipc-icon-button--onAccent2')\n",
    "    #button.click()\n",
    "\n",
    "    return {'name': name, 'release': release, 'stars': stars}\n",
    "\n",
    "\n",
    "pelis = list(map(parsePeli, elements))\n",
    "\n",
    "driver.close()\n",
    "\n",
    "filmsDf = pd.DataFrame(data=pelis)\n",
    "print(filmsDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desafío 12 - Nombre de la película, año y un breve resumen de las 10 películas aleatorias top (IMDB) como un dataframe de pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the url you will scrape in this exercise\n",
    "url = 'http://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(soup.find_all(\"span\", {\"class\": \"secondaryInfo\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         name                  release\n",
      "210     211. The Big Lebowski          1998\\n1h 57m\\nR\n",
      "174  175. Catch Me If You Can      2002\\n2h 21m\\nPG-13\n",
      "221        222. Before Sunset          2004\\n1h 20m\\nR\n",
      "199         200. Sherlock Jr.        1924\\n45m\\nPassed\n",
      "137        138. All About Eve   1950\\n2h 18m\\nApproved\n",
      "10           11. Forrest Gump      1994\\n2h 22m\\nPG-13\n",
      "84           85. High and Low  1963\\n2h 23m\\nNot Rated\n",
      "178  179. Million Dollar Baby      2004\\n2h 12m\\nPG-13\n",
      "47       48. The Intouchables          2011\\n1h 52m\\nR\n",
      "139       140. Shutter Island          2010\\n2h 18m\\nR\n"
     ]
    }
   ],
   "source": [
    "tenFilms = filmsDf.drop(columns=['stars'])\n",
    "tenFilms = tenFilms.sample(n=10)\n",
    "\n",
    "print(tenFilms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desafío 13 - Encontrar el reporte meteorológico en vivo (temperatura, velocidad del viento, descripción y clima) de una ciudad dada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://openweathermap.org/current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: Unable to locate element: div.current-container ; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\nRemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\nWebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:193:5\nNoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:511:5\ndom.find/</<@chrome://remote/content/shared/DOM.sys.mjs:136:16\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[470], line 27\u001b[0m\n\u001b[1;32m     18\u001b[0m     driver\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwind\u001b[39m\u001b[38;5;124m\"\u001b[39m: wind,\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m: desc,\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: t,\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcl\u001b[39m\u001b[38;5;124m\"\u001b[39m: cl\n\u001b[1;32m     25\u001b[0m     }\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mweather\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3129028\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[470], line 11\u001b[0m, in \u001b[0;36mweather\u001b[0;34m(city)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mweather\u001b[39m(city):\n\u001b[1;32m      9\u001b[0m     driver\u001b[38;5;241m.\u001b[39mget(url \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(city))\n\u001b[0;32m---> 11\u001b[0m     cont \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCSS_SELECTOR\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdiv.current-container \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     desc \u001b[38;5;241m=\u001b[39m cont\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv.bold\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m     14\u001b[0m     t \u001b[38;5;241m=\u001b[39m cont\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv.current-temp > span.heading\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:741\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    738\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[1;32m    739\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 741\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/selenium/webdriver/remote/errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mNoSuchElementException\u001b[0m: Message: Unable to locate element: div.current-container ; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\nRemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\nWebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:193:5\nNoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:511:5\ndom.find/</<@chrome://remote/content/shared/DOM.sys.mjs:136:16\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "url = 'https://openweathermap.org/city/'\n",
    "\n",
    "driver = webdriver.Firefox()\n",
    "\n",
    "def weather(city):\n",
    "    driver.get(url + str(city))\n",
    "\n",
    "    time.sleep(3)\n",
    "    cont = driver.find_element(By.CSS_SELECTOR,'div.current-container ')\n",
    "\n",
    "    desc = cont.find_element(By.CSS_SELECTOR,'div.bold').text\n",
    "    t = cont.find_element(By.CSS_SELECTOR,'div.current-temp > span.heading').text\n",
    "    wind = cont.find_element(By.CSS_SELECTOR,'div.wind-line').text\n",
    "    cl = cont.find_elements(By.CSS_SELECTOR,'ul.weather-items > li')[3].text\n",
    "\n",
    "    driver.close()\n",
    "\n",
    "    return {\n",
    "        \"wind\": wind,\n",
    "        \"description\": desc,\n",
    "        \"temperature\": t,\n",
    "        \"cl\": cl\n",
    "    }\n",
    "\n",
    "# A veces la página se bloquea\n",
    "print(weather(3129028))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desafío 14 - Nombre del libro, precio y disponibilidad de stock como un dataframe de pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise. \n",
    "# It is a fictional bookstore created to be scraped. \n",
    "url14 = 'http://books.toscrape.com/'\n",
    "books = requests.get(url11)\n",
    "soup = BeautifulSoup(books.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "libros = list(soup.select('h1.h3 a[tittle]'))\n",
    "#nombres = soup.select('h1.h3 a[tittle]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limitates tu output? Gracias! 🙂**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
